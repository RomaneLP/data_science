{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6fae56-e42a-4a62-b8d0-001ffb8de22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#commande à n'exécuter qu'une fois\n",
    "#os.chdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51aea818-78bd-463b-aed3-0621a693ee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'individus:  223\n"
     ]
    }
   ],
   "source": [
    "#on prend la liste des fichiers\n",
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "data = pd.read_csv(files[0])\n",
    "#la colonne +/- n'est pas prise en complte car on a pas sa moyenne pour les matchs de Wembenyama\n",
    "data = data.loc[:, data.columns!='+/-']\n",
    "#convertion des minutes par match en flottant\n",
    "data.loc[:,'MP'] = [float(x.split(':')[0])+ 0.006*float(x.split(':')[1]) for x in data.loc[:,'MP']]\n",
    "#concatenation de toutes les tables csv en un seul tableau\n",
    "for file in files[1:]:\n",
    "    match = pd.read_csv(file)\n",
    "    match = match.loc[:,match.columns!='+/-']\n",
    "    match.loc[:,'MP'] = [float(x.split(':')[0])+ 0.006*float(x.split(':')[1]) for x in match.loc[:,'MP']]\n",
    "    data = pd.concat([data,match])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"nombre d'individus: \", len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa99a4b8-5a56-4bde-9aef-79197ce7bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation des données manquantes\n",
    "#remplace les données absentes par une données de la même colonne, avec la même valeur pour la variable Résultat\n",
    "data_win = data[data['Résultat'] == 1]\n",
    "data_lose = data[data['Résultat'] != 1]\n",
    "for col in data_win.columns:\n",
    "    for i,rows in data_win.iterrows():\n",
    "        if pd.isna(data_win.loc[i,col]):\n",
    "            data_win.loc[i,col] = np.random.choice(data_win[data_win[col].notna()].loc[:,col])\n",
    "for col in data_lose.columns:\n",
    "    for i,rows in data_lose.iterrows():\n",
    "        if pd.isna(data_lose.loc[i,col]):\n",
    "            data_lose.loc[i,col] = np.random.choice(data_lose[data_lose[col].notna()].loc[:,col])\n",
    "data = pd.concat([data_win,data_lose])\n",
    "\n",
    "X_train = data.loc[:, data.columns!='Résultat']\n",
    "X_train = X_train.iloc[:,1:]\n",
    "Y = data.loc[:,'Résultat']\n",
    "VW = np.array([30.2 ,6.9 ,15.9 ,0.435 ,1.4 ,4.9 ,0.278 ,3.3 ,4.2 ,0.774 ,2.3 ,8.4 ,10.7 ,2.8 ,1.4 ,3.0 ,3.3 ,2.5 ,18.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb49a3d-3228-4aa6-82f3-6f7ea5e3ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation\n",
    "scaler = sk.preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa7c08ea-2f08-4caa-a474-e7d312496137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef de  Unnamed: 0 : -0.0625328483730836\n",
      "coef de  MP : 0.10657002570263815\n",
      "coef de  FG : -0.14345339199124466\n",
      "coef de  FGA : -0.04286816482726524\n",
      "coef de  FG% : 0.14365343380078707\n",
      "coef de  3P : -0.08139585349260567\n",
      "coef de  3PA : -0.06690390153742647\n",
      "coef de  3P% : -0.30486236419921153\n",
      "coef de  FT : 0.286212809304426\n",
      "coef de  FTA : 0.2611929013007886\n",
      "coef de  FT% : -0.01719680368100993\n",
      "coef de  ORB : 0.036889322667084036\n",
      "coef de  DRB : 0.021170008119222983\n",
      "coef de  TRB : 0.025254772536418543\n",
      "coef de  AST : 0.013604339727185692\n",
      "coef de  STL : 0.014538592579304208\n",
      "coef de  BLK : -0.018549194476233967\n",
      "coef de  TOV : 0.04562496778797842\n",
      "coef de  PF : 0.02485773358715399\n",
      "constante:  0.5112107623318386\n"
     ]
    }
   ],
   "source": [
    "#régression linéaire\n",
    "reg = LinearRegression().fit(X_scaled, Y)\n",
    "for k in range(len(reg.coef_)):\n",
    "    print('coef de ',data.columns[k], ':', reg.coef_[k])\n",
    "print('constante: ',reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19adb87b-c4d4-4a55-a1c8-ea75e574b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19)\n",
      "prédiction:  [0]\n",
      "proba de perdre:  0.999850053066774\n",
      "proba de gagner:  0.00014994693322600432\n"
     ]
    }
   ],
   "source": [
    "#régression logistique\n",
    "clf = LogisticRegression(random_state=0).fit(X_scaled, Y)\n",
    "VW = VW.reshape(1, -1)\n",
    "print(np.shape(VW))\n",
    "print('prédiction: ', clf.predict(VW))\n",
    "print('proba de perdre: ', clf.predict_proba(VW)[0][0])\n",
    "print('proba de gagner: ', clf.predict_proba(VW)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e9912f-ff50-494b-b872-e932ecbee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les résultats suivants ne sont pas consistants suivant la séparation entrainement/vérif\n",
      "prédiction:  [1]\n",
      "proba de perdre:  0.0\n",
      "proba de gagner:  1.0\n"
     ]
    }
   ],
   "source": [
    "#arbre de décision\n",
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = clf.fit(X_scaled, Y)\n",
    "print('Les résultats suivants ne sont pas consistants suivant la séparation entrainement/vérif')\n",
    "print('prédiction: ', clf.predict(VW))\n",
    "print('proba de perdre: ', clf.predict_proba(VW)[0][0])\n",
    "print('proba de gagner: ', clf.predict_proba(VW)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4bade8-6e66-4c38-9c0c-0ec0d6c9e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédiction:  [1]\n",
      "proba de perdre:  0.3287391598670345\n",
      "proba de gagner:  0.6712608401329656\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "clf = RandomForestClassifier(max_depth=2)\n",
    "clf.fit(X_scaled, Y)\n",
    "print('prédiction: ', clf.predict(VW))\n",
    "print('proba de perdre: ', clf.predict_proba(VW)[0][0])\n",
    "print('proba de gagner: ', clf.predict_proba(VW)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cfdc9-2189-4725-8006-56572774dccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
